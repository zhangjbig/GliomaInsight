{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import pandas as pd\n",
    "from scipy.stats import lognorm\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from Final_version_dl_4 import FeatureTransformer, PositionalEncoding, ResidualBlock, DeepRadiomicsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理列: CD40\n",
      "Predicted Labels: 0\n",
      "Probabilities: 5.2742729167221114e-05\n",
      "884.3461303710938 9.050606478237809e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86152\\AppData\\Local\\Temp\\ipykernel_32432\\1620772229.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理列: KYNU\n",
      "Predicted Labels: 0\n",
      "Probabilities: 5.2742729167221114e-05\n",
      "200.2667999267578 0.0007282601936289221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86152\\AppData\\Local\\Temp\\ipykernel_32432\\1620772229.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理列: CCRL2\n",
      "Predicted Labels: 0\n",
      "Probabilities: 5.2742729167221114e-05\n",
      "218.92381286621094 0.0003678631919846592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86152\\AppData\\Local\\Temp\\ipykernel_32432\\1620772229.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理列: FCGR2A\n",
      "Predicted Labels: 0\n",
      "Probabilities: 5.2742729167221114e-05\n",
      "3401.8720703125 6.073574079972765e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86152\\AppData\\Local\\Temp\\ipykernel_32432\\1620772229.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理列: JUNB\n",
      "Predicted Labels: 0\n",
      "Probabilities: 5.2742729167221114e-05\n",
      "16389.333984375 1.4687176126528248e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86152\\AppData\\Local\\Temp\\ipykernel_32432\\1620772229.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理列: MBOAT1\n",
      "Predicted Labels: 0\n",
      "Probabilities: 5.2742729167221114e-05\n",
      "442.07366943359375 0.00031546783674006834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86152\\AppData\\Local\\Temp\\ipykernel_32432\\1620772229.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    }
   ],
   "source": [
    "class PredictAndPlot:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # 调用模型预测\n",
    "    def prediction(self):\n",
    "        # current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "        # best_model_path = os.path.join(current_dir, \"dl_model/best_model_CCRL2.pth\")\n",
    "        best_model_path = \"dl_model/best_model_CCRL2.pth\"\n",
    "        model = FeatureTransformer(input_dim=14, d_model=32, nhead=4,\n",
    "                                   nhid=512, nlayers=3, dropout=0.1)  #### 这里的输入维度要和训练时一致\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(best_model_path))\n",
    "        except Exception as e:\n",
    "            print(f\"模型加载出错: {e}\")\n",
    "            return None, None\n",
    "        model.eval()\n",
    "\n",
    "        # data_path = os.path.join(current_dir, \"test.csv\")\n",
    "        df = pd.read_csv(\"test_example_data.csv\")\n",
    "        # print(f\"数据基本信息: {df.info()}\")\n",
    "        # print(f\"数据列数: {len(df.columns)}\")\n",
    "        scaler = StandardScaler()\n",
    "        input_data = torch.tensor(scaler.fit_transform(df.iloc[:, 4:18].values), dtype=torch.float32)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            probabilities = model(input_data)\n",
    "            predictions = (probabilities > 0.5).int()\n",
    "\n",
    "        pred_result = predictions.tolist()\n",
    "        probability = probabilities.tolist()\n",
    "\n",
    "        print(\"Predicted Labels:\", pred_result)\n",
    "        print(\"Probabilities:\", probability)\n",
    "\n",
    "        return predictions, probabilities\n",
    "\n",
    "    # 初始化数据\n",
    "    def plot_dynamic_curve(self, x, y, colname, new_x=None, new_y=None):\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.patch.set_facecolor((15 / 255, 29 / 255, 43 / 255))\n",
    "        ax.set_facecolor((15 / 255, 29 / 255, 43 / 255))\n",
    "\n",
    "        ax.spines['bottom'].set_color((141 / 255, 185 / 255, 252 / 255))\n",
    "        ax.spines['left'].set_color((141 / 255, 185 / 255, 252 / 255))\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "        ax.tick_params(colors=(141 / 255, 185 / 255, 252 / 255))\n",
    "        ax.set_xlabel(\"Gene Expression Level\", fontsize=12, color=(141 / 255, 185 / 255, 252 / 255))\n",
    "        ax.set_ylabel(f\"Probability of {colname} Expression Level\", fontsize=12, color=(141 / 255, 185 / 255, 252 / 255))\n",
    "\n",
    "        line, = ax.plot([], [], color=(141 / 255, 185 / 255, 252 / 255), lw=2)\n",
    "\n",
    "        def init():\n",
    "            ax.set_xlim(min(x), max(x))\n",
    "            ax.set_ylim(min(y), max(y))\n",
    "            line.set_data([], [])\n",
    "            return line,\n",
    "\n",
    "        def update(frame):\n",
    "            line.set_data(x[:frame], y[:frame])\n",
    "            return line,\n",
    "\n",
    "        ani = animation.FuncAnimation(fig, update, frames=len(x) + 1, init_func=init, interval=20, repeat=False)\n",
    "\n",
    "        # 处理额外曲线\n",
    "        if new_x is not None and new_y is not None:\n",
    "            new_x = np.atleast_1d(new_x)\n",
    "            new_y = np.atleast_1d(new_y)\n",
    "\n",
    "            sorted_indices = np.argsort(new_x)\n",
    "            new_x_sorted = new_x[sorted_indices]\n",
    "            new_y_sorted = new_y[sorted_indices]\n",
    "\n",
    "            if len(new_x_sorted) > 1:  # 只有多个点时才进行插值\n",
    "                # 生成扰动数据\n",
    "                perturbation = np.random.normal(scale=0.05 * np.max(new_y_sorted), size=len(new_y_sorted))\n",
    "                new_y_perturbed = new_y_sorted + perturbation\n",
    "                new_y_perturbed = np.clip(new_y_perturbed, 0, None)  # 保证概率不为负\n",
    "\n",
    "                # 平滑处理\n",
    "                spline = make_interp_spline(new_x_sorted, new_y_perturbed, k=3)\n",
    "                smooth_x = np.linspace(min(new_x_sorted), max(new_x_sorted), 300)\n",
    "                smooth_y = spline(smooth_x)\n",
    "\n",
    "                ax.plot(smooth_x, smooth_y, color=\"#D0D7E1\", lw=2)\n",
    "            else:\n",
    "                ax.scatter(new_x_sorted, new_y_sorted, color=\"#D0D7E1\", marker=\"o\", label=\"Perturbed Point\")\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def main(self):\n",
    "        # current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "        # data = pd.read_csv(os.path.join(current_dir, \"TPM_CGGA.csv\"))\n",
    "        data = pd.read_csv(\"TPM_CGGA.csv\")\n",
    "        LogNorm = ['TRAM2']\n",
    "        Gamma = ['CD40', 'KYNU', 'CCRL2', 'FCGR2A', 'JUNB', 'MBOAT1']\n",
    "        for col_name in Gamma:\n",
    "            print(f\"正在处理列: {col_name}\")\n",
    "            # 拟合 Gamma 分布\n",
    "            data_column = data[col_name]\n",
    "            shape, loc, scale = stats.gamma.fit(data_column)\n",
    "            if(col_name == 'CD40'):\n",
    "                shape = 3.2443377626673273\n",
    "                scale = 794.5733995413987\n",
    "            x = np.linspace(min(data_column), max(data_column), 100)\n",
    "            y = stats.gamma.pdf(x, shape, loc, scale)\n",
    "\n",
    "            # 进行预测\n",
    "            predictions, probabilities = self.prediction()\n",
    "            if predictions is None or probabilities is None:\n",
    "                continue\n",
    "\n",
    "            # 数据转化\n",
    "            max_level = max(data_column)\n",
    "            min_level = min(data_column)\n",
    "            x_new = probabilities*(max_level-min_level)*1000+min_level\n",
    "            y_new = stats.gamma.pdf(x_new, shape, loc, scale)\n",
    "\n",
    "            print(x_new.item(),y_new)\n",
    "            # self.plot_dynamic_curve(x, y, col_name,x_new.item(),y_new)\n",
    "            # break\n",
    "\n",
    "        # for col_name in LogNorm:\n",
    "        #     print(f\"正在处理列: {col_name}\")\n",
    "        #     # 拟合对数正态分布\n",
    "        #     data_column = data[col_name]\n",
    "        #     shape, loc, scale = lognorm.fit(data_column)\n",
    "            \n",
    "        #     x = np.linspace(min(data_column), 200, 100)\n",
    "        #     print(max(data_column))\n",
    "        #     y = lognorm.pdf(x, shape, loc, scale)\n",
    "\n",
    "        #     self.plot_dynamic_curve(x, y,col_name)\n",
    "        #     # plot_dynamic_curve(x, y, new_x, new_y)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    a = PredictAndPlot()\n",
    "    a.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
